{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5b6975",
   "metadata": {},
   "source": [
    "# STAMP: Short-Term Attention/Memory Priority Model for Session-based Recommendation(STAMP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7853e0c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df2c4b",
   "metadata": {},
   "source": [
    "### class 관계\n",
    "\n",
    "* [AbstractRecommender](https://github.com/RUCAIBox/RecBole/blob/master/recbole/model/abstract_recommender.py#L25)  \n",
    "    * [SequentialRecommender](https://github.com/RUCAIBox/RecBole/blob/master/recbole/model/abstract_recommender.py#L146)\n",
    "        * [STAMP](https://github.com/RUCAIBox/RecBole/blob/master/recbole/model/sequential_recommender/stamp.py)\n",
    "         \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882fd13e",
   "metadata": {},
   "source": [
    "### Recbole STAMP 코드실행 예시([참고](https://github.com/RUCAIBox/RecBole/blob/master/run_example/sequential-model-fixed-missing-last-item.ipynb))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4109605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recbole SASRec 코드실행 예시 \n",
    "\n",
    "# 1. config \n",
    "from recbole.config import Config\n",
    "parameter_dict = {\n",
    "    'data_path': './data',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'user_inter_num_interval': \"[30,inf)\",\n",
    "    'item_inter_num_interval': \"[40,inf)\",\n",
    "    'load_col': {'inter': ['user_id', 'item_id', 'timestamp']},\n",
    "    'train_neg_sample_args': None,\n",
    "    'epochs': 1,\n",
    "    'eval_args': {\n",
    "        'split': {'RS': [10, 0, 0]},\n",
    "        'group_by': 'user',\n",
    "        'order': 'TO',\n",
    "        'mode': 'full'}\n",
    "}\n",
    "config = Config(model='STAMP', dataset='recbox_data', config_dict=parameter_dict) \n",
    "\n",
    "# 2. dataset \n",
    "from recbole.data import create_dataset, data_preparation\n",
    "dataset = create_dataset(config)\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "# 3. model\n",
    "from recbole.model.sequential_recommender import STAMP\n",
    "model = STAMP(config, train_data.dataset).to(config['device']) \n",
    "\n",
    "# # 4. training \n",
    "# from recbole.trainer import Trainer\n",
    "# trainer = Trainer(config, model)\n",
    "# best_valid_score, best_valid_result = trainer.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe205f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STAMP(\n",
       "  (item_embedding): Embedding(10962, 64, padding_idx=0)\n",
       "  (w1): Linear(in_features=64, out_features=64, bias=False)\n",
       "  (w2): Linear(in_features=64, out_features=64, bias=False)\n",
       "  (w3): Linear(in_features=64, out_features=64, bias=False)\n",
       "  (w0): Linear(in_features=64, out_features=1, bias=False)\n",
       "  (mlp_a): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (mlp_b): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       "  (loss_fct): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3a8aa",
   "metadata": {},
   "source": [
    "### train data 예시([참고](https://github.com/RUCAIBox/RecBole/blob/master/recbole/trainer/trainer.py#L234))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6faccf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch_data in enumerate(train_data):\n",
    "    batch_idx = batch_idx\n",
    "    interaction = batch_data\n",
    "    break\n",
    "\n",
    "USER_ID = 'user_id'\n",
    "POS_ITEM_ID = 'item_id'\n",
    "ITEM_SEQ = 'item_id_list'\n",
    "ITEM_SEQ_LEN = 'item_length'\n",
    "\n",
    "user_seq = interaction[USER_ID] \n",
    "item_seq = interaction[ITEM_SEQ]         \n",
    "item_seq_len = interaction[ITEM_SEQ_LEN] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b92b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8681,  4622, 22968,  ..., 30080, 19206,   759])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_seq # torch.Size([2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6db6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1868,   266,  2206,  ...,     0,     0,     0],\n",
       "        [ 2549,  2549,    60,  ...,     0,     0,     0],\n",
       "        [ 1017,   522,   265,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 4208,   818,  6991,  ...,     0,     0,     0],\n",
       "        [ 3813,  4103,  4103,  ...,  9211, 10242,   265],\n",
       "        [  181,  1299,  1076,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_seq # torch.Size([2048, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ef9b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 26, 13,  ..., 39, 50,  7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_seq_len # torch.Size([2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8196a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eb6230e",
   "metadata": {},
   "source": [
    "* 유저 8681 학습데이터 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54fffc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The batch_size of interaction: 39\n",
       "    user_id, torch.Size([39]), cpu, torch.int64\n",
       "    item_id, torch.Size([39]), cpu, torch.int64\n",
       "    timestamp, torch.Size([39]), cpu, torch.float32\n",
       "    item_length, torch.Size([39]), cpu, torch.int64\n",
       "    item_id_list, torch.Size([39, 50]), cpu, torch.int64\n",
       "    timestamp_list, torch.Size([39, 50]), cpu, torch.float32\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "uid = train_data.dataset.id2token(train_data.dataset.uid_field, [8681])[0]\n",
    "index = np.isin(train_data.dataset[train_data.dataset.uid_field].numpy(), 8681) \n",
    "\n",
    "user_interaction = train_data.dataset[index]\n",
    "user_interaction\n",
    "\n",
    "# df = pd.read_csv('./data/recbox_data/recbox_data.inter', sep='\\t')\n",
    "# ex = df[df['user_id:token'] == uid] # 유저 8681의 로그는 총 42개 (이중 39개가 train data로 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "745859ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681,\n",
       "        8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681,\n",
       "        8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681, 8681,\n",
       "        8681, 8681, 8681])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_interaction[USER_ID] # torch.Size([39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8ec5d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1868,    0,    0,  ...,    0,    0,    0],\n",
       "        [1868,  266,    0,  ...,    0,    0,    0],\n",
       "        [1868,  266, 2206,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [1868,  266, 2206,  ...,    0,    0,    0],\n",
       "        [1868,  266, 2206,  ...,    0,    0,    0],\n",
       "        [1868,  266, 2206,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x\n",
    "user_interaction[ITEM_SEQ] # torch.Size([39, 50]) max sequence length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35ba7737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1868,   266,  2206,  2488,   439,  6038,  5231,  5693,    39,  6429,\n",
       "         1234,  5944,  3629,   173,  8296,  7010,  6897,  6897,   106,  3858,\n",
       "         3858,  1196,   643,  5705,  4854,  7869,  8703,  3170,  9258,  9774,\n",
       "         9362, 10102, 10440, 10334,  8651, 10242,  6997, 10610, 10465,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_interaction[ITEM_SEQ][-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3871d799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  266,  2206,  2488,   439,  6038,  5231,  5693,    39,  6429,  1234,\n",
       "         5944,  3629,   173,  8296,  7010,  6897,  6897,   106,  3858,  3858,\n",
       "         1196,   643,  5705,  4854,  7869,  8703,  3170,  9258,  9774,  9362,\n",
       "        10102, 10440, 10334,  8651, 10242,  6997, 10610, 10465,  2939])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y(label)\n",
    "user_interaction[POS_ITEM_ID] # torch.Size([39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27e9db33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "        37, 38, 39])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_interaction[ITEM_SEQ_LEN] # torch.Size([39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2319a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a95a1a82",
   "metadata": {},
   "source": [
    "### SequentialRecommender class\n",
    "* [code](https://github.com/RUCAIBox/RecBole/blob/master/recbole/model/abstract_recommender.py#L146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "194d4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ba8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialRecommender(AbstractRecommender):\n",
    "    \"\"\"\n",
    "    This is a abstract sequential recommender. All the sequential model should implement This class.\n",
    "    \"\"\"\n",
    "    type = ModelType.SEQUENTIAL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd7a9d7",
   "metadata": {},
   "source": [
    "```python\n",
    "def __init__(self, config, dataset):\n",
    "        super(SequentialRecommender, self).__init__()\n",
    "\n",
    "        # load dataset info\n",
    "        self.USER_ID = config[\"USER_ID_FIELD\"]\n",
    "        self.ITEM_ID = config[\"ITEM_ID_FIELD\"]\n",
    "        self.ITEM_SEQ = self.ITEM_ID + config[\"LIST_SUFFIX\"]\n",
    "        self.ITEM_SEQ_LEN = config[\"ITEM_LIST_LENGTH_FIELD\"]\n",
    "        self.POS_ITEM_ID = self.ITEM_ID\n",
    "        self.NEG_ITEM_ID = config[\"NEG_PREFIX\"] + self.ITEM_ID\n",
    "        self.max_seq_length = config[\"MAX_ITEM_LIST_LENGTH\"]\n",
    "        self.n_items = dataset.num(self.ITEM_ID)\n",
    "\n",
    "        # load parameters info\n",
    "        self.device = config[\"device\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b0cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER_ID: user_id\n",
      "ITEM_ID: item_id\n",
      "ITEM_SEQ: item_id_list\n",
      "ITEM_SEQ_LEN: item_length\n",
      "POS_ITEM_ID: item_id\n",
      "NEG_ITEM_ID: neg_item_id\n",
      "max_seq_length: 50\n",
      "n_items: 10962\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "# load dataset info\n",
    "USER_ID = config[\"USER_ID_FIELD\"] \n",
    "ITEM_ID = config[\"ITEM_ID_FIELD\"]  \n",
    "ITEM_SEQ = ITEM_ID + config[\"LIST_SUFFIX\"]\n",
    "ITEM_SEQ_LEN = config[\"ITEM_LIST_LENGTH_FIELD\"]\n",
    "\n",
    "POS_ITEM_ID = ITEM_ID\n",
    "NEG_ITEM_ID = config[\"NEG_PREFIX\"] + ITEM_ID\n",
    "\n",
    "max_seq_length = config[\"MAX_ITEM_LIST_LENGTH\"]\n",
    "n_items = dataset.num(ITEM_ID)\n",
    "\n",
    "# load parameters info\n",
    "device = config[\"device\"]\n",
    "\n",
    "print('USER_ID:', USER_ID)\n",
    "print('ITEM_ID:', ITEM_ID)\n",
    "print('ITEM_SEQ:', ITEM_SEQ)\n",
    "print('ITEM_SEQ_LEN:', ITEM_SEQ_LEN)\n",
    "print('POS_ITEM_ID:', POS_ITEM_ID)\n",
    "print('NEG_ITEM_ID:', NEG_ITEM_ID)\n",
    "print('max_seq_length:', max_seq_length)\n",
    "print('n_items:', n_items)\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d46f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d810fa82",
   "metadata": {},
   "source": [
    "```python\n",
    " def get_attention_mask(self, item_seq, bidirectional=False):\n",
    "        \"\"\"Generate left-to-right uni-directional or bidirectional attention mask for multi-head attention.\"\"\"\n",
    "        attention_mask = item_seq != 0\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)  # torch.bool\n",
    "        if not bidirectional:\n",
    "            extended_attention_mask = torch.tril(\n",
    "                extended_attention_mask.expand((-1, -1, item_seq.size(-1), -1))\n",
    "            )\n",
    "        extended_attention_mask = torch.where(extended_attention_mask, 0.0, -10000.0)\n",
    "        return extended_attention_mask\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e6a5ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1868,   266,  2206,  ...,     0,     0,     0],\n",
       "        [ 2549,  2549,    60,  ...,     0,     0,     0],\n",
       "        [ 1017,   522,   265,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 4208,   818,  6991,  ...,     0,     0,     0],\n",
       "        [ 3813,  4103,  4103,  ...,  9211, 10242,   265],\n",
       "        [  181,  1299,  1076,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input \n",
    "item_seq  # torch.Size([2048, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "badde40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1868,  266, 2206, 2488,  439, 6038, 5231,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3462a422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True,  True,  True,  ..., False, False, False]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = item_seq != 0  # torch.Size([2048, 50])\n",
    "attention_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87919b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c5b92fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True,  True,  True,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True,  ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True,  ..., False, False, False]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2) # torch.Size([2048, 1, 50]) -> torch.Size([2048, 1, 1, 50])\n",
    "extended_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc29fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional = False\n",
    "if not bidirectional:\n",
    "    tmp = extended_attention_mask.expand((-1, -1, item_seq.size(-1), -1)) # torch.Size([2048, 1, 50, 50])\n",
    "    extended_attention_mask = torch.tril(tmp)                             # torch.Size([2048, 1, 50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac995424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True,  ...,  True,  True,  True],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ...,  True,  True,  True],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = extended_attention_mask.expand((-1, -1, item_seq.size(-1), -1)) # torch.Size([2048, 1, 50, 50])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9372ad07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0][0] # # torch.Size([50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1457772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True, False, False,  ..., False, False, False],\n",
       "          [ True,  True, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[ True, False, False,  ..., False, False, False],\n",
       "          [ True,  True, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[ True, False, False,  ..., False, False, False],\n",
       "          [ True,  True, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ True, False, False,  ..., False, False, False],\n",
       "          [ True,  True, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False]]],\n",
       "\n",
       "\n",
       "        [[[ True, False, False,  ..., False, False, False],\n",
       "          [ True,  True, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ...,  True, False, False],\n",
       "          [ True,  True,  True,  ...,  True,  True, False],\n",
       "          [ True,  True,  True,  ...,  True,  True,  True]]],\n",
       "\n",
       "\n",
       "        [[[ True, False, False,  ..., False, False, False],\n",
       "          [ True,  True, False,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          ...,\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False],\n",
       "          [ True,  True,  True,  ..., False, False, False]]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask = torch.tril(tmp) # torch.Size([2048, 1, 50, 50])\n",
    "extended_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efe393d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ec21e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86748b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask[0][0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5dcf5ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask[0][0][7] # 7 ~ 49까지 동일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d060f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask[0][0][49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6bce3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_attention_mask = torch.where(extended_attention_mask, 0.0, -10000.0) # torch.Size([2048, 1, 50, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7db30cb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[     0., -10000., -10000.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0., -10000.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          ...,\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.]]],\n",
       "\n",
       "\n",
       "        [[[     0., -10000., -10000.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0., -10000.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          ...,\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.]]],\n",
       "\n",
       "\n",
       "        [[[     0., -10000., -10000.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0., -10000.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          ...,\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[     0., -10000., -10000.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0., -10000.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          ...,\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.]]],\n",
       "\n",
       "\n",
       "        [[[     0., -10000., -10000.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0., -10000.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          ...,\n",
       "          [     0.,      0.,      0.,  ...,      0., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ...,      0.,      0., -10000.],\n",
       "          [     0.,      0.,      0.,  ...,      0.,      0.,      0.]]],\n",
       "\n",
       "\n",
       "        [[[     0., -10000., -10000.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0., -10000.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          ...,\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.],\n",
       "          [     0.,      0.,      0.,  ..., -10000., -10000., -10000.]]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b111b5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c028a248",
   "metadata": {},
   "source": [
    "```python\n",
    " def gather_indexes(self, output, gather_index):\n",
    "        \"\"\"Gathers the vectors at the specific positions over a minibatch\"\"\"\n",
    "        gather_index = gather_index.view(-1, 1, 1).expand(-1, -1, output.shape[-1])\n",
    "        output_tensor = output.gather(dim=1, index=gather_index)\n",
    "        return output_tensor.squeeze(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4a7575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input \n",
    "output = torch.rand([2048, 50, 64]) # output 예시\n",
    "gather_index = item_seq_len - 1     # torch.Size([2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69384345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 25, 12,  ..., 38, 49,  6])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gather_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2e668c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6,  6,  6,  ...,  6,  6,  6]],\n",
       "\n",
       "        [[25, 25, 25,  ..., 25, 25, 25]],\n",
       "\n",
       "        [[12, 12, 12,  ..., 12, 12, 12]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[38, 38, 38,  ..., 38, 38, 38]],\n",
       "\n",
       "        [[49, 49, 49,  ..., 49, 49, 49]],\n",
       "\n",
       "        [[ 6,  6,  6,  ...,  6,  6,  6]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gather_index = gather_index.view(-1, 1, 1).expand(-1, -1, output.shape[-1]) # torch.Size([2048, 1, 1]) -> [2048, 1, 64]\n",
    "gather_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "821f76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = output.gather(dim=1, index=gather_index) # torch.Size([2048, 1, 64])\n",
    "\n",
    "# output[0][6]\n",
    "# output[1][25]\n",
    "# ...\n",
    "# output[2047][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "01417fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0320, 0.4300, 0.1542,  ..., 0.1900, 0.8480, 0.5424]],\n",
       "\n",
       "        [[0.3069, 0.4541, 0.0528,  ..., 0.8476, 0.6264, 0.6698]],\n",
       "\n",
       "        [[0.0131, 0.2552, 0.2702,  ..., 0.0176, 0.9185, 0.1752]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7754, 0.5159, 0.2408,  ..., 0.2827, 0.5453, 0.8278]],\n",
       "\n",
       "        [[0.8666, 0.7152, 0.2644,  ..., 0.1230, 0.5616, 0.8798]],\n",
       "\n",
       "        [[0.6902, 0.2934, 0.7709,  ..., 0.3917, 0.8086, 0.0504]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9a133f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0320, 0.4300, 0.1542, 0.0019, 0.3915, 0.0605, 0.1935, 0.6811, 0.5048,\n",
       "        0.3541, 0.6980, 0.4920, 0.4206, 0.1087, 0.1328, 0.2339, 0.0416, 0.4659,\n",
       "        0.7262, 0.5235, 0.0957, 0.5303, 0.6733, 0.7423, 0.9876, 0.5838, 0.1462,\n",
       "        0.7638, 0.6565, 0.3153, 0.6075, 0.4204, 0.0161, 0.0368, 0.7844, 0.0072,\n",
       "        0.5428, 0.8369, 0.2896, 0.3736, 0.8334, 0.6844, 0.2207, 0.3696, 0.0388,\n",
       "        0.9414, 0.8661, 0.6743, 0.4789, 0.2714, 0.4282, 0.6675, 0.1873, 0.0504,\n",
       "        0.5365, 0.9650, 0.1889, 0.7426, 0.0550, 0.3698, 0.6055, 0.1900, 0.8480,\n",
       "        0.5424])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1fbaf04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3069, 0.4541, 0.0528, 0.7933, 0.7326, 0.9650, 0.4293, 0.9217, 0.0565,\n",
       "        0.1969, 0.7149, 0.6095, 0.5099, 0.5188, 0.8574, 0.8394, 0.0267, 0.6900,\n",
       "        0.3555, 0.2192, 0.2323, 0.1542, 0.0817, 0.1590, 0.0681, 0.8346, 0.7143,\n",
       "        0.3378, 0.2859, 0.7785, 0.9668, 0.8525, 0.0838, 0.4283, 0.4188, 0.2971,\n",
       "        0.5262, 0.4591, 0.9092, 0.6489, 0.6712, 0.7706, 0.7793, 0.5896, 0.7011,\n",
       "        0.9960, 0.3039, 0.4623, 0.9865, 0.3380, 0.6413, 0.6226, 0.4300, 0.7187,\n",
       "        0.6727, 0.4492, 0.6484, 0.8844, 0.3546, 0.3703, 0.8179, 0.8476, 0.6264,\n",
       "        0.6698])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5428692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = output_tensor.squeeze(1) # torch.Size([2048, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9312fd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0320, 0.4300, 0.1542,  ..., 0.1900, 0.8480, 0.5424],\n",
       "        [0.3069, 0.4541, 0.0528,  ..., 0.8476, 0.6264, 0.6698],\n",
       "        [0.0131, 0.2552, 0.2702,  ..., 0.0176, 0.9185, 0.1752],\n",
       "        ...,\n",
       "        [0.7754, 0.5159, 0.2408,  ..., 0.2827, 0.5453, 0.8278],\n",
       "        [0.8666, 0.7152, 0.2644,  ..., 0.1230, 0.5616, 0.8798],\n",
       "        [0.6902, 0.2934, 0.7709,  ..., 0.3917, 0.8086, 0.0504]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749a3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409a5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a909bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "104d95f7",
   "metadata": {},
   "source": [
    "### STAMP class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ca309",
   "metadata": {},
   "source": [
    "* AbstractRecommender\n",
    "    * SequentialRecommender\n",
    "        * STAMP\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92921e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.init import normal_\n",
    "\n",
    "from recbole.model.abstract_recommender import SequentialRecommender\n",
    "from recbole.model.loss import BPRLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STAMP(SequentialRecommender):\n",
    "    r\"\"\"STAMP is capable of capturing users’ general interests from the long-term memory of a session context,\n",
    "    whilst taking into account users’ current interests from the short-term memory of the last-clicks.\n",
    "\n",
    "\n",
    "    Note:\n",
    "        According to the test results, we made a little modification to the score function mentioned in the paper,\n",
    "        and did not use the final sigmoid activation function.\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadaf968",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "def __init__(self, config, dataset):\n",
    "    super(STAMP, self).__init__(config, dataset)\n",
    "\n",
    "    # load parameters info\n",
    "    self.embedding_size = config[\"embedding_size\"]\n",
    "\n",
    "    # define layers and loss\n",
    "    self.item_embedding = nn.Embedding(\n",
    "        self.n_items, self.embedding_size, padding_idx=0\n",
    "    )\n",
    "    self.w1 = nn.Linear(self.embedding_size, self.embedding_size, bias=False)\n",
    "    self.w2 = nn.Linear(self.embedding_size, self.embedding_size, bias=False)\n",
    "    self.w3 = nn.Linear(self.embedding_size, self.embedding_size, bias=False)\n",
    "    self.w0 = nn.Linear(self.embedding_size, 1, bias=False)\n",
    "    self.b_a = nn.Parameter(torch.zeros(self.embedding_size), requires_grad=True)\n",
    "    self.mlp_a = nn.Linear(self.embedding_size, self.embedding_size, bias=True)\n",
    "    self.mlp_b = nn.Linear(self.embedding_size, self.embedding_size, bias=True)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.tanh = nn.Tanh()\n",
    "    self.loss_type = config[\"loss_type\"]\n",
    "    if self.loss_type == \"BPR\":\n",
    "        self.loss_fct = BPRLoss()\n",
    "    elif self.loss_type == \"CE\":\n",
    "        self.loss_fct = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        raise NotImplementedError(\"Make sure 'loss_type' in ['BPR', 'CE']!\")\n",
    "\n",
    "    # # parameters initialization\n",
    "    self.apply(self._init_weights)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88afa5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load parameters info\n",
    "embedding_size = config[\"embedding_size\"]\n",
    "embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a583dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define layers\n",
    "item_embedding = nn.Embedding(n_items, embedding_size, padding_idx=0)\n",
    "\n",
    "## attention machanism weight\n",
    "w0 = nn.Linear(embedding_size, 1, bias=False)\n",
    "w1 = nn.Linear(embedding_size, embedding_size, bias=False)\n",
    "w2 = nn.Linear(embedding_size, embedding_size, bias=False)\n",
    "w3 = nn.Linear(embedding_size, embedding_size, bias=False)\n",
    "b_a = nn.Parameter(torch.zeros(embedding_size), requires_grad=True)\n",
    "\n",
    "## mlp\n",
    "mlp_a = nn.Linear(embedding_size, embedding_size, bias=True)\n",
    "mlp_b = nn.Linear(embedding_size, embedding_size, bias=True)\n",
    "\n",
    "sigmoid = nn.Sigmoid()\n",
    "tanh = nn.Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06b574d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss \n",
    "loss_type = config[\"loss_type\"]\n",
    "if loss_type == \"BPR\":\n",
    "    loss_fct = BPRLoss()\n",
    "elif loss_type == \"CE\":\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    raise NotImplementedError(\"Make sure 'loss_type' in ['BPR', 'CE']!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725cbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters initialization\n",
    "apply(self._init_weights)\n",
    "\n",
    "# 해당 코드와 동일하게 작동\n",
    "# for submodule in model.children():\n",
    "#     _init_weights(submodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284fd33b",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "def _init_weights(self, module):\n",
    "    if isinstance(module, nn.Embedding):\n",
    "        normal_(module.weight.data, 0, 0.002)\n",
    "    elif isinstance(module, nn.Linear):\n",
    "        normal_(module.weight.data, 0, 0.05)\n",
    "        if module.bias is not None:\n",
    "            module.bias.data.fill_(0.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c9bbda",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "def forward(self, item_seq, item_seq_len):\n",
    "    item_seq_emb = self.item_embedding(item_seq)\n",
    "    last_inputs = self.gather_indexes(item_seq_emb, item_seq_len - 1)\n",
    "    org_memory = item_seq_emb\n",
    "    ms = torch.div(torch.sum(org_memory, dim=1), item_seq_len.unsqueeze(1).float())\n",
    "    alpha = self.count_alpha(org_memory, last_inputs, ms)\n",
    "    vec = torch.matmul(alpha.unsqueeze(1), org_memory)\n",
    "    ma = vec.squeeze(1) + ms\n",
    "    hs = self.tanh(self.mlp_a(ma))\n",
    "    ht = self.tanh(self.mlp_b(last_inputs))\n",
    "    seq_output = hs * ht\n",
    "    return seq_output\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa149f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1868,   266,  2206,  ...,     0,     0,     0],\n",
       "        [ 2549,  2549,    60,  ...,     0,     0,     0],\n",
       "        [ 1017,   522,   265,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 4208,   818,  6991,  ...,     0,     0,     0],\n",
       "        [ 3813,  4103,  4103,  ...,  9211, 10242,   265],\n",
       "        [  181,  1299,  1076,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_seq # torch.Size([2048, 50]) batch_size, max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c477af2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3531,  0.1079, -0.0826,  ...,  2.1116,  1.5943,  0.9022],\n",
       "         [-0.0926, -1.5311, -1.1752,  ...,  1.8774,  0.1764, -0.6408],\n",
       "         [ 2.7649, -0.3843,  0.6599,  ...,  0.9337,  0.6107,  0.6867],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0785,  0.2606, -1.2229,  ...,  0.9491, -0.1844,  1.5269],\n",
       "         [ 0.0785,  0.2606, -1.2229,  ...,  0.9491, -0.1844,  1.5269],\n",
       "         [-0.6542,  1.4045, -0.9057,  ...,  0.9867,  0.2270,  0.9651],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.5249, -0.0755, -1.8381,  ...,  0.6181, -3.1122, -0.2412],\n",
       "         [ 0.7290, -1.2760, -0.4319,  ...,  0.4882,  0.6424, -1.1781],\n",
       "         [ 1.9577, -1.6954, -0.2121,  ...,  0.4650,  1.4187,  0.6217],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1258,  1.4504, -0.0402,  ..., -0.0353,  0.9443,  2.2611],\n",
       "         [ 0.0345, -0.6507,  0.7060,  ...,  0.9454, -0.0822,  0.8135],\n",
       "         [-1.2123,  0.0193, -0.3518,  ...,  0.0877,  0.0082,  0.0863],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.1233,  0.6645, -0.1376,  ...,  1.6094, -0.3381,  0.7211],\n",
       "         [ 1.3468,  0.9643, -0.9193,  ..., -0.5588, -0.6747,  0.3088],\n",
       "         [ 1.3468,  0.9643, -0.9193,  ..., -0.5588, -0.6747,  0.3088],\n",
       "         ...,\n",
       "         [ 1.2804,  0.3661,  0.3252,  ..., -0.2420,  1.7446,  0.4820],\n",
       "         [-2.2557,  0.3089,  0.0392,  ..., -0.2034, -0.2066,  0.1409],\n",
       "         [ 1.9577, -1.6954, -0.2121,  ...,  0.4650,  1.4187,  0.6217]],\n",
       "\n",
       "        [[-1.4250, -0.0204,  0.1084,  ..., -1.4141,  0.0340, -0.2631],\n",
       "         [ 0.4765,  0.1920, -0.4105,  ...,  0.2747, -0.2612, -1.6236],\n",
       "         [ 0.4780,  0.8130,  1.8602,  ...,  0.9746, -0.6859, -0.6357],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_seq_emb = item_embedding(item_seq) # torch.Size([2048, 50, 64])\n",
    "org_memory = item_seq_emb\n",
    "\n",
    "item_seq_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cf7e51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4458, -1.3469,  0.0455,  ..., -0.4465, -0.3475,  2.3354],\n",
       "        [ 0.0329,  2.5744,  0.6203,  ..., -0.8717, -1.5073, -0.3776],\n",
       "        [-0.8985,  0.3676,  1.8222,  ..., -0.2688,  0.1008,  2.1990],\n",
       "        ...,\n",
       "        [ 1.6410, -0.2803,  0.6968,  ..., -1.0407, -0.1854, -0.1268],\n",
       "        [ 1.9577, -1.6954, -0.2121,  ...,  0.4650,  1.4187,  0.6217],\n",
       "        [ 1.3527,  1.5362,  0.1002,  ...,  0.7500, -1.9779,  0.6683]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gather_indexes( output, gather_index):\n",
    "        \"\"\"Gathers the vectors at the specific positions over a minibatch\"\"\"\n",
    "        gather_index = gather_index.view(-1, 1, 1).expand(-1, -1, output.shape[-1])\n",
    "        output_tensor = output.gather(dim=1, index=gather_index)\n",
    "        return output_tensor.squeeze(1)\n",
    "\n",
    "last_inputs = gather_indexes(item_seq_emb, item_seq_len - 1) # item_seq_len - 1 인덱스 행 가져오기 \n",
    "last_inputs # torch.Size([2048, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2099d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0602, -0.5067,  0.2281,  ...,  0.4464,  0.2637,  0.9053],\n",
       "        [-0.0492,  0.4845, -0.4089,  ..., -0.2129, -0.2832,  0.4292],\n",
       "        [-0.0764, -0.6103,  0.0675,  ..., -0.1303, -0.2001,  0.3318],\n",
       "        ...,\n",
       "        [ 0.0443,  0.1398, -0.2464,  ...,  0.0652, -0.2164,  0.1868],\n",
       "        [ 0.2123, -0.2032, -0.0776,  ..., -0.0422,  0.1022,  0.2967],\n",
       "        [-0.0197,  0.4879,  0.2212,  ..., -0.1135, -0.8879, -0.1351]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# longterm memory \n",
    "\n",
    "ms = torch.div(torch.sum(org_memory, dim=1), item_seq_len.unsqueeze(1).float())\n",
    "ms # torch.Size([2048, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "917c002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention mechanism \n",
    "\n",
    "# alpha = count_alpha(org_memory, last_inputs, ms) # x_i, x_t, m_s \n",
    "alpha = torch.rand([2048, 50])                     # 아래 참고 \n",
    "ma = torch.matmul(alpha.unsqueeze(1), org_memory)  # torch.Size([2048, 1, 50]) x torch.Size([2048, 50, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9766a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp cell\n",
    "hs = tanh(mlp_a(ma)).squeeze(1)  # torch.Size([2048, 64])\n",
    "ht = tanh(mlp_b(last_inputs))    # torch.Size([2048, 64])\n",
    "seq_output = hs * ht             # torch.Size([2048, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bfe4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a1cebc0",
   "metadata": {},
   "source": [
    "```python\n",
    "def count_alpha(self, context, aspect, output):\n",
    "        r\"\"\"This is a function that count the attention weights\n",
    "\n",
    "        Args:\n",
    "            context(torch.FloatTensor): Item list embedding matrix, shape of [batch_size, time_steps, emb]\n",
    "            aspect(torch.FloatTensor): The embedding matrix of the last click item, shape of [batch_size, emb]\n",
    "            output(torch.FloatTensor): The average of the context, shape of [batch_size, emb]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor:attention weights, shape of [batch_size, time_steps]\n",
    "        \"\"\"\n",
    "        timesteps = context.size(1)\n",
    "        aspect_3dim = aspect.repeat(1, timesteps).view(\n",
    "            -1, timesteps, self.embedding_size\n",
    "        )\n",
    "        output_3dim = output.repeat(1, timesteps).view(\n",
    "            -1, timesteps, self.embedding_size\n",
    "        )\n",
    "        res_ctx = self.w1(context)\n",
    "        res_asp = self.w2(aspect_3dim)\n",
    "        res_output = self.w3(output_3dim)\n",
    "        res_sum = res_ctx + res_asp + res_output + self.b_a\n",
    "        res_act = self.w0(self.sigmoid(res_sum))\n",
    "        alpha = res_act.squeeze(2)\n",
    "        return alpha\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e6d0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input \n",
    "context = org_memory # x_i\n",
    "aspect = last_inputs # x_t torch.Size([2048, 64])\n",
    "output = ms          # m_s torch.Size([2048, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c80be0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = context.size(1) # 50\n",
    "aspect_3dim = aspect.repeat(1, timesteps).view(-1, timesteps, embedding_size) # torch.Size([2048, 3200])-> torch.Size([2048, 50, 64])\n",
    "output_3dim = output.repeat(1, timesteps).view(-1, timesteps, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37b0c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ctx = w1(context)         # W1 * x_i  torch.Size([2048, 50, 64])\n",
    "res_asp = w2(aspect_3dim)     # W2 * x_t  torch.Size([2048, 50, 64])\n",
    "res_output = w3(output_3dim)  # W3 * m_s  torch.Size([2048, 50, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8411e7d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3875e+00, -4.6703e-01,  6.2192e-01,  ..., -4.0820e-01,\n",
       "           5.6535e-01, -5.2281e-01],\n",
       "         [ 5.5756e-01, -1.4719e-01, -4.1336e-01,  ...,  7.6941e-01,\n",
       "          -7.7056e-01, -7.6560e-01],\n",
       "         [-7.1844e-01,  4.8012e-01, -1.1105e+00,  ..., -7.3048e-01,\n",
       "          -5.8200e-01, -1.0103e+00],\n",
       "         ...,\n",
       "         [ 1.2692e-01, -6.6955e-01, -5.0031e-01,  ...,  8.1640e-01,\n",
       "          -7.1951e-01, -3.6567e-01],\n",
       "         [ 1.2692e-01, -6.6955e-01, -5.0031e-01,  ...,  8.1640e-01,\n",
       "          -7.1951e-01, -3.6567e-01],\n",
       "         [ 1.2692e-01, -6.6955e-01, -5.0031e-01,  ...,  8.1640e-01,\n",
       "          -7.1951e-01, -3.6567e-01]],\n",
       "\n",
       "        [[-3.8064e-01,  5.0792e-01,  3.7935e-02,  ...,  7.9792e-01,\n",
       "          -4.0008e-01,  2.3094e-01],\n",
       "         [-3.8064e-01,  5.0792e-01,  3.7935e-02,  ...,  7.9792e-01,\n",
       "          -4.0008e-01,  2.3094e-01],\n",
       "         [ 7.6625e-02, -6.7121e-01, -9.1939e-01,  ..., -6.3593e-01,\n",
       "          -2.5423e-01,  1.2693e+00],\n",
       "         ...,\n",
       "         [-3.1710e-01,  1.6582e-01, -2.8127e-02,  ..., -4.1626e-01,\n",
       "          -9.4881e-01,  3.0227e-01],\n",
       "         [-3.1710e-01,  1.6582e-01, -2.8127e-02,  ..., -4.1626e-01,\n",
       "          -9.4881e-01,  3.0227e-01],\n",
       "         [-3.1710e-01,  1.6582e-01, -2.8127e-02,  ..., -4.1626e-01,\n",
       "          -9.4881e-01,  3.0227e-01]],\n",
       "\n",
       "        [[-1.3787e+00, -7.4488e-01, -1.2697e-01,  ...,  1.1237e+00,\n",
       "          -5.8637e-01, -9.5686e-01],\n",
       "         [ 3.7313e-01,  9.4240e-01,  3.9069e-01,  ...,  8.9565e-01,\n",
       "           2.7099e-01, -1.3484e+00],\n",
       "         [-6.5324e-01,  2.3185e-01,  1.5648e+00,  ..., -9.8155e-02,\n",
       "           1.0799e+00, -1.2457e+00],\n",
       "         ...,\n",
       "         [-3.1720e-01, -3.4119e-01,  3.3915e-01,  ...,  2.5528e-01,\n",
       "          -3.8154e-01, -9.8950e-01],\n",
       "         [-3.1720e-01, -3.4119e-01,  3.3915e-01,  ...,  2.5528e-01,\n",
       "          -3.8154e-01, -9.8950e-01],\n",
       "         [-3.1720e-01, -3.4119e-01,  3.3915e-01,  ...,  2.5528e-01,\n",
       "          -3.8154e-01, -9.8950e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.0530e-01, -1.9802e+00,  1.5864e-02,  ...,  7.3136e-01,\n",
       "           2.3816e-01, -4.4841e-02],\n",
       "         [ 1.1558e-01, -1.4071e+00,  1.5793e-02,  ...,  8.9556e-02,\n",
       "          -9.6417e-02,  4.5103e-01],\n",
       "         [ 7.8183e-01, -2.9297e+00, -4.9091e-01,  ...,  5.1254e-04,\n",
       "           9.6432e-01,  6.5705e-01],\n",
       "         ...,\n",
       "         [-9.9380e-02, -6.5093e-01, -2.9249e-01,  ...,  9.9981e-03,\n",
       "           6.5638e-01, -3.6718e-01],\n",
       "         [-9.9380e-02, -6.5093e-01, -2.9249e-01,  ...,  9.9981e-03,\n",
       "           6.5638e-01, -3.6718e-01],\n",
       "         [-9.9380e-02, -6.5093e-01, -2.9249e-01,  ...,  9.9981e-03,\n",
       "           6.5638e-01, -3.6718e-01]],\n",
       "\n",
       "        [[-1.3616e-01, -3.4718e-01, -5.5594e-01,  ..., -8.3343e-01,\n",
       "          -9.1372e-02, -3.6041e-01],\n",
       "         [-3.4285e-01, -1.2070e-01, -5.2633e-01,  ...,  1.6362e+00,\n",
       "           7.1802e-01,  9.8224e-01],\n",
       "         [-3.4285e-01, -1.2070e-01, -5.2633e-01,  ...,  1.6362e+00,\n",
       "           7.1802e-01,  9.8224e-01],\n",
       "         ...,\n",
       "         [-2.5372e-01, -9.4269e-01, -1.2394e-01,  ...,  7.3917e-01,\n",
       "           4.8279e-01,  4.8616e-01],\n",
       "         [ 2.6936e-01, -1.2685e+00,  3.2671e-01,  ...,  1.0496e+00,\n",
       "           6.4490e-01,  1.2050e+00],\n",
       "         [-2.9605e-01,  3.5103e-01,  1.2110e+00,  ...,  1.9419e-01,\n",
       "           1.6839e+00,  6.1424e-02]],\n",
       "\n",
       "        [[ 5.7203e-01, -2.1197e+00, -8.2904e-01,  ..., -8.8943e-01,\n",
       "           6.8973e-01,  1.3471e+00],\n",
       "         [ 7.3039e-01, -1.8186e+00,  8.6320e-01,  ...,  6.4040e-01,\n",
       "          -8.8977e-02,  1.1459e-01],\n",
       "         [ 3.0061e-02, -8.7878e-01,  3.9107e-01,  ...,  6.8343e-01,\n",
       "           5.4147e-01,  1.2096e+00],\n",
       "         ...,\n",
       "         [ 7.2814e-01, -1.5990e+00,  3.2171e-01,  ..., -5.0953e-01,\n",
       "           4.0939e-01,  2.7888e-01],\n",
       "         [ 7.2814e-01, -1.5990e+00,  3.2171e-01,  ..., -5.0953e-01,\n",
       "           4.0939e-01,  2.7888e-01],\n",
       "         [ 7.2814e-01, -1.5990e+00,  3.2171e-01,  ..., -5.0953e-01,\n",
       "           4.0939e-01,  2.7888e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_sum = res_ctx + res_asp + res_output + b_a #  torch.Size([2048, 50, 64])\n",
    "res_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cefa44a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0125],\n",
       "         [-0.2338],\n",
       "         [ 0.0077],\n",
       "         ...,\n",
       "         [-0.1970],\n",
       "         [-0.1970],\n",
       "         [-0.1970]],\n",
       "\n",
       "        [[-0.1639],\n",
       "         [-0.1639],\n",
       "         [-0.1499],\n",
       "         ...,\n",
       "         [-0.1744],\n",
       "         [-0.1744],\n",
       "         [-0.1744]],\n",
       "\n",
       "        [[-0.3336],\n",
       "         [-0.1058],\n",
       "         [-0.3249],\n",
       "         ...,\n",
       "         [-0.2879],\n",
       "         [-0.2879],\n",
       "         [-0.2879]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3936],\n",
       "         [-0.4166],\n",
       "         [-0.3106],\n",
       "         ...,\n",
       "         [-0.2892],\n",
       "         [-0.2892],\n",
       "         [-0.2892]],\n",
       "\n",
       "        [[-0.2170],\n",
       "         [-0.2404],\n",
       "         [-0.2404],\n",
       "         ...,\n",
       "         [-0.2515],\n",
       "         [-0.2047],\n",
       "         [-0.2671]],\n",
       "\n",
       "        [[-0.0733],\n",
       "         [-0.3106],\n",
       "         [-0.1488],\n",
       "         ...,\n",
       "         [-0.2250],\n",
       "         [-0.2250],\n",
       "         [-0.2250]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_act = w0(sigmoid(res_sum)) # torch.Size([2048, 50, 1])\n",
    "res_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81f80429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0125, -0.2338,  0.0077,  ..., -0.1970, -0.1970, -0.1970],\n",
       "        [-0.1639, -0.1639, -0.1499,  ..., -0.1744, -0.1744, -0.1744],\n",
       "        [-0.3336, -0.1058, -0.3249,  ..., -0.2879, -0.2879, -0.2879],\n",
       "        ...,\n",
       "        [-0.3936, -0.4166, -0.3106,  ..., -0.2892, -0.2892, -0.2892],\n",
       "        [-0.2170, -0.2404, -0.2404,  ..., -0.2515, -0.2047, -0.2671],\n",
       "        [-0.0733, -0.3106, -0.1488,  ..., -0.2250, -0.2250, -0.2250]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = res_act.squeeze(2) # torch.Size([2048, 50])\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45357058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecaf46b1",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "def calculate_loss(self, interaction):\n",
    "    item_seq = interaction[self.ITEM_SEQ]\n",
    "    item_seq_len = interaction[self.ITEM_SEQ_LEN]\n",
    "    seq_output = self.forward(item_seq, item_seq_len)\n",
    "    pos_items = interaction[self.POS_ITEM_ID]\n",
    "    if self.loss_type == \"BPR\":\n",
    "        neg_items = interaction[self.NEG_ITEM_ID]\n",
    "        pos_items_emb = self.item_embedding(pos_items)\n",
    "        neg_items_emb = self.item_embedding(neg_items)\n",
    "        pos_score = torch.sum(seq_output * pos_items_emb, dim=-1)  # [B]\n",
    "        neg_score = torch.sum(seq_output * neg_items_emb, dim=-1)  # [B]\n",
    "        loss = self.loss_fct(pos_score, neg_score)\n",
    "        return loss\n",
    "    else:  # self.loss_type = 'CE'\n",
    "        test_item_emb = self.item_embedding.weight\n",
    "        logits = torch.matmul(seq_output, test_item_emb.transpose(0, 1))\n",
    "        loss = self.loss_fct(logits, pos_items)\n",
    "        return loss\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40c74acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_seq = interaction[ITEM_SEQ]\n",
    "item_seq_len = interaction[ITEM_SEQ_LEN]\n",
    "# seq_output = self.forward(item_seq, item_seq_len)\n",
    "pos_items = interaction[POS_ITEM_ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e5f088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entorpy loss \n",
    "test_item_emb = item_embedding.weight # torch.Size([10962, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da58c96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -3.8363, -3.7135,  ...,  1.2520, -1.9060,  1.2944],\n",
       "        [ 0.0000, -2.4076, -0.7629,  ..., -1.0999, -5.1167,  0.9964],\n",
       "        [ 0.0000, -0.1450,  0.3902,  ...,  0.8573,  0.5835, -0.0851],\n",
       "        ...,\n",
       "        [ 0.0000, -3.3026, -2.7665,  ..., -1.2535,  4.1188,  0.1657],\n",
       "        [ 0.0000, -0.8994,  0.3988,  ...,  5.6830, -1.6246, -3.0343],\n",
       "        [ 0.0000, -4.0702, -0.0350,  ..., -2.4813,  2.2666, -0.0387]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.matmul(seq_output, test_item_emb.transpose(0, 1)) # torch.Size([2048, 64]) x torch.Size([64, 10962])\n",
    "logits # torch.Size([2048, 10962])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13f850cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.0119, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fct(logits, pos_items)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fdc8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9ab26f4",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "def predict(self, interaction):\n",
    "    item_seq = interaction[self.ITEM_SEQ]\n",
    "    item_seq_len = interaction[self.ITEM_SEQ_LEN]\n",
    "    test_item = interaction[self.ITEM_ID]\n",
    "    seq_output = self.forward(item_seq, item_seq_len)\n",
    "    test_item_emb = self.item_embedding(test_item)\n",
    "    scores = torch.mul(seq_output, test_item_emb).sum(dim=1)  # [B]\n",
    "    return scores\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffe1b69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1868,   266,  2206,  ...,     0,     0,     0],\n",
       "        [ 2549,  2549,    60,  ...,     0,     0,     0],\n",
       "        [ 1017,   522,   265,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 4208,   818,  6991,  ...,     0,     0,     0],\n",
       "        [ 3813,  4103,  4103,  ...,  9211, 10242,   265],\n",
       "        [  181,  1299,  1076,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_seq = interaction[ITEM_SEQ]\n",
    "item_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b982b53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 26, 13,  ..., 39, 50,  7])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_seq_len = interaction[ITEM_SEQ_LEN]\n",
    "item_seq_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ce670e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5693, 4209, 7263,  ...,  231, 1751, 7948])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_item = interaction[ITEM_ID] # prediction item_id_lst\n",
    "test_item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61626fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def full_sort_predict(self, interaction):\n",
    "    item_seq = interaction[self.ITEM_SEQ]\n",
    "    item_seq_len = interaction[self.ITEM_SEQ_LEN]\n",
    "    seq_output = self.forward(item_seq, item_seq_len)\n",
    "    test_items_emb = self.item_embedding.weight\n",
    "    scores = torch.matmul(seq_output, test_items_emb.transpose(0, 1))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4df949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7112ea56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f192b728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b5078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a889f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310b4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938c77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2462508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
